{"ast":null,"code":"import { getCurrentScope } from '../../currentScopes.js';\nimport { captureException } from '../../exports.js';\nimport { startSpan } from '../../tracing/trace.js';\nimport { GEN_AI_OPERATION_NAME_ATTRIBUTE, GEN_AI_REQUEST_MODEL_ATTRIBUTE, GEN_AI_REQUEST_TEMPERATURE_ATTRIBUTE, GEN_AI_REQUEST_TOP_P_ATTRIBUTE, GEN_AI_REQUEST_FREQUENCY_PENALTY_ATTRIBUTE, GEN_AI_REQUEST_PRESENCE_PENALTY_ATTRIBUTE, GEN_AI_REQUEST_MESSAGES_ATTRIBUTE, GEN_AI_RESPONSE_TEXT_ATTRIBUTE, GEN_AI_SYSTEM_ATTRIBUTE, GEN_AI_RESPONSE_FINISH_REASONS_ATTRIBUTE, GEN_AI_RESPONSE_ID_ATTRIBUTE, OPENAI_RESPONSE_ID_ATTRIBUTE, GEN_AI_RESPONSE_MODEL_ATTRIBUTE, OPENAI_RESPONSE_MODEL_ATTRIBUTE, OPENAI_RESPONSE_TIMESTAMP_ATTRIBUTE, GEN_AI_USAGE_INPUT_TOKENS_ATTRIBUTE, OPENAI_USAGE_PROMPT_TOKENS_ATTRIBUTE, GEN_AI_USAGE_OUTPUT_TOKENS_ATTRIBUTE, OPENAI_USAGE_COMPLETION_TOKENS_ATTRIBUTE, GEN_AI_USAGE_TOTAL_TOKENS_ATTRIBUTE } from '../gen-ai-attributes.js';\nimport { OPENAI_INTEGRATION_NAME } from './constants.js';\nimport { shouldInstrument, getOperationName, getSpanOperation, isChatCompletionResponse, isResponsesApiResponse, buildMethodPath } from './utils.js';\n\n/**\n * Extract request attributes from method arguments\n */\nfunction extractRequestAttributes(args, methodPath) {\n  const attributes = {\n    [GEN_AI_SYSTEM_ATTRIBUTE]: 'openai',\n    [GEN_AI_OPERATION_NAME_ATTRIBUTE]: getOperationName(methodPath)\n  };\n  if (args.length > 0 && typeof args[0] === 'object' && args[0] !== null) {\n    const params = args[0];\n    attributes[GEN_AI_REQUEST_MODEL_ATTRIBUTE] = params.model ?? 'unknown';\n    if ('temperature' in params) attributes[GEN_AI_REQUEST_TEMPERATURE_ATTRIBUTE] = params.temperature;\n    if ('top_p' in params) attributes[GEN_AI_REQUEST_TOP_P_ATTRIBUTE] = params.top_p;\n    if ('frequency_penalty' in params) attributes[GEN_AI_REQUEST_FREQUENCY_PENALTY_ATTRIBUTE] = params.frequency_penalty;\n    if ('presence_penalty' in params) attributes[GEN_AI_REQUEST_PRESENCE_PENALTY_ATTRIBUTE] = params.presence_penalty;\n  } else {\n    attributes[GEN_AI_REQUEST_MODEL_ATTRIBUTE] = 'unknown';\n  }\n  return attributes;\n}\n\n/**\n * Helper function to set token usage attributes\n */\nfunction setTokenUsageAttributes(span, promptTokens, completionTokens, totalTokens) {\n  if (promptTokens !== undefined) {\n    span.setAttributes({\n      [OPENAI_USAGE_PROMPT_TOKENS_ATTRIBUTE]: promptTokens,\n      [GEN_AI_USAGE_INPUT_TOKENS_ATTRIBUTE]: promptTokens\n    });\n  }\n  if (completionTokens !== undefined) {\n    span.setAttributes({\n      [OPENAI_USAGE_COMPLETION_TOKENS_ATTRIBUTE]: completionTokens,\n      [GEN_AI_USAGE_OUTPUT_TOKENS_ATTRIBUTE]: completionTokens\n    });\n  }\n  if (totalTokens !== undefined) {\n    span.setAttributes({\n      [GEN_AI_USAGE_TOTAL_TOKENS_ATTRIBUTE]: totalTokens\n    });\n  }\n}\n\n/**\n * Helper function to set common response attributes (ID, model, timestamp)\n */\nfunction setCommonResponseAttributes(span, id, model, timestamp) {\n  if (id) {\n    span.setAttributes({\n      [OPENAI_RESPONSE_ID_ATTRIBUTE]: id,\n      [GEN_AI_RESPONSE_ID_ATTRIBUTE]: id\n    });\n  }\n  if (model) {\n    span.setAttributes({\n      [OPENAI_RESPONSE_MODEL_ATTRIBUTE]: model,\n      [GEN_AI_RESPONSE_MODEL_ATTRIBUTE]: model\n    });\n  }\n  if (timestamp) {\n    span.setAttributes({\n      [OPENAI_RESPONSE_TIMESTAMP_ATTRIBUTE]: new Date(timestamp * 1000).toISOString()\n    });\n  }\n}\n\n/**\n * Add attributes for Chat Completion responses\n */\nfunction addChatCompletionAttributes(span, response) {\n  setCommonResponseAttributes(span, response.id, response.model, response.created);\n  if (response.usage) {\n    setTokenUsageAttributes(span, response.usage.prompt_tokens, response.usage.completion_tokens, response.usage.total_tokens);\n  }\n  if (Array.isArray(response.choices)) {\n    const finishReasons = response.choices.map(choice => choice.finish_reason).filter(reason => reason !== null);\n    if (finishReasons.length > 0) {\n      span.setAttributes({\n        [GEN_AI_RESPONSE_FINISH_REASONS_ATTRIBUTE]: JSON.stringify(finishReasons)\n      });\n    }\n  }\n}\n\n/**\n * Add attributes for Responses API responses\n */\nfunction addResponsesApiAttributes(span, response) {\n  setCommonResponseAttributes(span, response.id, response.model, response.created_at);\n  if (response.status) {\n    span.setAttributes({\n      [GEN_AI_RESPONSE_FINISH_REASONS_ATTRIBUTE]: JSON.stringify([response.status])\n    });\n  }\n  if (response.usage) {\n    setTokenUsageAttributes(span, response.usage.input_tokens, response.usage.output_tokens, response.usage.total_tokens);\n  }\n}\n\n/**\n * Add response attributes to spans\n * This currently supports both Chat Completion and Responses API responses\n */\nfunction addResponseAttributes(span, result, recordOutputs) {\n  if (!result || typeof result !== 'object') return;\n  const response = result;\n  if (isChatCompletionResponse(response)) {\n    addChatCompletionAttributes(span, response);\n    if (recordOutputs && response.choices?.length) {\n      const responseTexts = response.choices.map(choice => choice.message?.content || '');\n      span.setAttributes({\n        [GEN_AI_RESPONSE_TEXT_ATTRIBUTE]: JSON.stringify(responseTexts)\n      });\n    }\n  } else if (isResponsesApiResponse(response)) {\n    addResponsesApiAttributes(span, response);\n    if (recordOutputs && response.output_text) {\n      span.setAttributes({\n        [GEN_AI_RESPONSE_TEXT_ATTRIBUTE]: response.output_text\n      });\n    }\n  }\n}\n\n// Extract and record AI request inputs, if present. This is intentionally separate from response attributes.\nfunction addRequestAttributes(span, params) {\n  if ('messages' in params) {\n    span.setAttributes({\n      [GEN_AI_REQUEST_MESSAGES_ATTRIBUTE]: JSON.stringify(params.messages)\n    });\n  }\n  if ('input' in params) {\n    span.setAttributes({\n      [GEN_AI_REQUEST_MESSAGES_ATTRIBUTE]: JSON.stringify(params.input)\n    });\n  }\n}\nfunction getOptionsFromIntegration() {\n  const scope = getCurrentScope();\n  const client = scope.getClient();\n  const integration = client?.getIntegrationByName(OPENAI_INTEGRATION_NAME);\n  const shouldRecordInputsAndOutputs = integration ? Boolean(client?.getOptions().sendDefaultPii) : false;\n  return {\n    recordInputs: integration?.options?.recordInputs ?? shouldRecordInputsAndOutputs,\n    recordOutputs: integration?.options?.recordOutputs ?? shouldRecordInputsAndOutputs\n  };\n}\n\n/**\n * Instrument a method with Sentry spans\n * Following Sentry AI Agents Manual Instrumentation conventions\n * @see https://docs.sentry.io/platforms/javascript/guides/node/tracing/instrumentation/ai-agents-module/#manual-instrumentation\n */\nfunction instrumentMethod(originalMethod, methodPath, context, options) {\n  return async function instrumentedMethod() {\n    for (var _len = arguments.length, args = new Array(_len), _key = 0; _key < _len; _key++) {\n      args[_key] = arguments[_key];\n    }\n    const finalOptions = options || getOptionsFromIntegration();\n    const requestAttributes = extractRequestAttributes(args, methodPath);\n    const model = requestAttributes[GEN_AI_REQUEST_MODEL_ATTRIBUTE] || 'unknown';\n    const operationName = getOperationName(methodPath);\n    return startSpan({\n      name: `${operationName} ${model}`,\n      op: getSpanOperation(methodPath),\n      attributes: requestAttributes\n    }, async span => {\n      try {\n        if (finalOptions.recordInputs && args[0] && typeof args[0] === 'object') {\n          addRequestAttributes(span, args[0]);\n        }\n        const result = await originalMethod.apply(context, args);\n        // TODO: Add streaming support\n        addResponseAttributes(span, result, finalOptions.recordOutputs);\n        return result;\n      } catch (error) {\n        captureException(error);\n        throw error;\n      }\n    });\n  };\n}\n\n/**\n * Create a deep proxy for OpenAI client instrumentation\n */\nfunction createDeepProxy(target) {\n  let currentPath = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : '';\n  let options = arguments.length > 2 ? arguments[2] : undefined;\n  return new Proxy(target, {\n    get(obj, prop) {\n      const value = obj[prop];\n      const methodPath = buildMethodPath(currentPath, String(prop));\n      if (typeof value === 'function' && shouldInstrument(methodPath)) {\n        return instrumentMethod(value, methodPath, obj, options);\n      }\n      if (value && typeof value === 'object') {\n        return createDeepProxy(value, methodPath, options);\n      }\n      return value;\n    }\n  });\n}\n\n/**\n * Instrument an OpenAI client with Sentry tracing\n * Can be used across Node.js, Cloudflare Workers, and Vercel Edge\n */\nfunction instrumentOpenAiClient(client, options) {\n  return createDeepProxy(client, '', options);\n}\nexport { instrumentOpenAiClient };\n//# sourceMappingURL=index.js.map","map":null,"metadata":{},"sourceType":"module","externalDependencies":[]}