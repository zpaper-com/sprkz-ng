{"ast":null,"code":"import { getCurrentScope } from '../../currentScopes.js';\nimport { captureException } from '../../exports.js';\nimport { startSpan } from '../../tracing/trace.js';\nimport { GEN_AI_OPERATION_NAME_ATTRIBUTE, GEN_AI_REQUEST_MODEL_ATTRIBUTE, GEN_AI_REQUEST_TEMPERATURE_ATTRIBUTE, GEN_AI_REQUEST_TOP_P_ATTRIBUTE, GEN_AI_REQUEST_FREQUENCY_PENALTY_ATTRIBUTE, GEN_AI_REQUEST_PRESENCE_PENALTY_ATTRIBUTE, GEN_AI_REQUEST_MESSAGES_ATTRIBUTE, GEN_AI_RESPONSE_TEXT_ATTRIBUTE, GEN_AI_SYSTEM_ATTRIBUTE, GEN_AI_RESPONSE_FINISH_REASONS_ATTRIBUTE, GEN_AI_RESPONSE_ID_ATTRIBUTE, OPENAI_RESPONSE_ID_ATTRIBUTE, GEN_AI_RESPONSE_MODEL_ATTRIBUTE, OPENAI_RESPONSE_MODEL_ATTRIBUTE, OPENAI_RESPONSE_TIMESTAMP_ATTRIBUTE, GEN_AI_USAGE_INPUT_TOKENS_ATTRIBUTE, OPENAI_USAGE_PROMPT_TOKENS_ATTRIBUTE, GEN_AI_USAGE_OUTPUT_TOKENS_ATTRIBUTE, OPENAI_USAGE_COMPLETION_TOKENS_ATTRIBUTE, GEN_AI_USAGE_TOTAL_TOKENS_ATTRIBUTE } from '../gen-ai-attributes.js';\nimport { OPENAI_INTEGRATION_NAME } from './constants.js';\nimport { shouldInstrument, getOperationName, getSpanOperation, isChatCompletionResponse, isResponsesApiResponse, buildMethodPath } from './utils.js';\n\n/**\n * Extract request attributes from method arguments\n */\nfunction extractRequestAttributes(args, methodPath) {\n  const attributes = {\n    [GEN_AI_SYSTEM_ATTRIBUTE]: 'openai',\n    [GEN_AI_OPERATION_NAME_ATTRIBUTE]: getOperationName(methodPath)\n  };\n  if (args.length > 0 && typeof args[0] === 'object' && args[0] !== null) {\n    const params = args[0];\n    attributes[GEN_AI_REQUEST_MODEL_ATTRIBUTE] = params.model ?? 'unknown';\n    if ('temperature' in params) attributes[GEN_AI_REQUEST_TEMPERATURE_ATTRIBUTE] = params.temperature;\n    if ('top_p' in params) attributes[GEN_AI_REQUEST_TOP_P_ATTRIBUTE] = params.top_p;\n    if ('frequency_penalty' in params) attributes[GEN_AI_REQUEST_FREQUENCY_PENALTY_ATTRIBUTE] = params.frequency_penalty;\n    if ('presence_penalty' in params) attributes[GEN_AI_REQUEST_PRESENCE_PENALTY_ATTRIBUTE] = params.presence_penalty;\n  } else {\n    attributes[GEN_AI_REQUEST_MODEL_ATTRIBUTE] = 'unknown';\n  }\n  return attributes;\n}\n\n/**\n * Helper function to set token usage attributes\n */\nfunction setTokenUsageAttributes(span, promptTokens, completionTokens, totalTokens) {\n  if (promptTokens !== undefined) {\n    span.setAttributes({\n      [OPENAI_USAGE_PROMPT_TOKENS_ATTRIBUTE]: promptTokens,\n      [GEN_AI_USAGE_INPUT_TOKENS_ATTRIBUTE]: promptTokens\n    });\n  }\n  if (completionTokens !== undefined) {\n    span.setAttributes({\n      [OPENAI_USAGE_COMPLETION_TOKENS_ATTRIBUTE]: completionTokens,\n      [GEN_AI_USAGE_OUTPUT_TOKENS_ATTRIBUTE]: completionTokens\n    });\n  }\n  if (totalTokens !== undefined) {\n    span.setAttributes({\n      [GEN_AI_USAGE_TOTAL_TOKENS_ATTRIBUTE]: totalTokens\n    });\n  }\n}\n\n/**\n * Helper function to set common response attributes (ID, model, timestamp)\n */\nfunction setCommonResponseAttributes(span, id, model, timestamp) {\n  if (id) {\n    span.setAttributes({\n      [OPENAI_RESPONSE_ID_ATTRIBUTE]: id,\n      [GEN_AI_RESPONSE_ID_ATTRIBUTE]: id\n    });\n  }\n  if (model) {\n    span.setAttributes({\n      [OPENAI_RESPONSE_MODEL_ATTRIBUTE]: model,\n      [GEN_AI_RESPONSE_MODEL_ATTRIBUTE]: model\n    });\n  }\n  if (timestamp) {\n    span.setAttributes({\n      [OPENAI_RESPONSE_TIMESTAMP_ATTRIBUTE]: new Date(timestamp * 1000).toISOString()\n    });\n  }\n}\n\n/**\n * Add attributes for Chat Completion responses\n */\nfunction addChatCompletionAttributes(span, response) {\n  setCommonResponseAttributes(span, response.id, response.model, response.created);\n  if (response.usage) {\n    setTokenUsageAttributes(span, response.usage.prompt_tokens, response.usage.completion_tokens, response.usage.total_tokens);\n  }\n  if (Array.isArray(response.choices)) {\n    const finishReasons = response.choices.map(choice => choice.finish_reason).filter(reason => reason !== null);\n    if (finishReasons.length > 0) {\n      span.setAttributes({\n        [GEN_AI_RESPONSE_FINISH_REASONS_ATTRIBUTE]: JSON.stringify(finishReasons)\n      });\n    }\n  }\n}\n\n/**\n * Add attributes for Responses API responses\n */\nfunction addResponsesApiAttributes(span, response) {\n  setCommonResponseAttributes(span, response.id, response.model, response.created_at);\n  if (response.status) {\n    span.setAttributes({\n      [GEN_AI_RESPONSE_FINISH_REASONS_ATTRIBUTE]: JSON.stringify([response.status])\n    });\n  }\n  if (response.usage) {\n    setTokenUsageAttributes(span, response.usage.input_tokens, response.usage.output_tokens, response.usage.total_tokens);\n  }\n}\n\n/**\n * Add response attributes to spans\n * This currently supports both Chat Completion and Responses API responses\n */\nfunction addResponseAttributes(span, result, recordOutputs) {\n  if (!result || typeof result !== 'object') return;\n  const response = result;\n  if (isChatCompletionResponse(response)) {\n    addChatCompletionAttributes(span, response);\n    if (recordOutputs && response.choices?.length) {\n      const responseTexts = response.choices.map(choice => choice.message?.content || '');\n      span.setAttributes({\n        [GEN_AI_RESPONSE_TEXT_ATTRIBUTE]: JSON.stringify(responseTexts)\n      });\n    }\n  } else if (isResponsesApiResponse(response)) {\n    addResponsesApiAttributes(span, response);\n    if (recordOutputs && response.output_text) {\n      span.setAttributes({\n        [GEN_AI_RESPONSE_TEXT_ATTRIBUTE]: response.output_text\n      });\n    }\n  }\n}\n\n// Extract and record AI request inputs, if present. This is intentionally separate from response attributes.\nfunction addRequestAttributes(span, params) {\n  if ('messages' in params) {\n    span.setAttributes({\n      [GEN_AI_REQUEST_MESSAGES_ATTRIBUTE]: JSON.stringify(params.messages)\n    });\n  }\n  if ('input' in params) {\n    span.setAttributes({\n      [GEN_AI_REQUEST_MESSAGES_ATTRIBUTE]: JSON.stringify(params.input)\n    });\n  }\n}\nfunction getOptionsFromIntegration() {\n  const scope = getCurrentScope();\n  const client = scope.getClient();\n  const integration = client?.getIntegrationByName(OPENAI_INTEGRATION_NAME);\n  const shouldRecordInputsAndOutputs = integration ? Boolean(client?.getOptions().sendDefaultPii) : false;\n  return {\n    recordInputs: integration?.options?.recordInputs ?? shouldRecordInputsAndOutputs,\n    recordOutputs: integration?.options?.recordOutputs ?? shouldRecordInputsAndOutputs\n  };\n}\n\n/**\n * Instrument a method with Sentry spans\n * Following Sentry AI Agents Manual Instrumentation conventions\n * @see https://docs.sentry.io/platforms/javascript/guides/node/tracing/instrumentation/ai-agents-module/#manual-instrumentation\n */\nfunction instrumentMethod(originalMethod, methodPath, context, options) {\n  return async function instrumentedMethod(...args) {\n    const finalOptions = options || getOptionsFromIntegration();\n    const requestAttributes = extractRequestAttributes(args, methodPath);\n    const model = requestAttributes[GEN_AI_REQUEST_MODEL_ATTRIBUTE] || 'unknown';\n    const operationName = getOperationName(methodPath);\n    return startSpan({\n      name: `${operationName} ${model}`,\n      op: getSpanOperation(methodPath),\n      attributes: requestAttributes\n    }, async span => {\n      try {\n        if (finalOptions.recordInputs && args[0] && typeof args[0] === 'object') {\n          addRequestAttributes(span, args[0]);\n        }\n        const result = await originalMethod.apply(context, args);\n        // TODO: Add streaming support\n        addResponseAttributes(span, result, finalOptions.recordOutputs);\n        return result;\n      } catch (error) {\n        captureException(error);\n        throw error;\n      }\n    });\n  };\n}\n\n/**\n * Create a deep proxy for OpenAI client instrumentation\n */\nfunction createDeepProxy(target, currentPath = '', options) {\n  return new Proxy(target, {\n    get(obj, prop) {\n      const value = obj[prop];\n      const methodPath = buildMethodPath(currentPath, String(prop));\n      if (typeof value === 'function' && shouldInstrument(methodPath)) {\n        return instrumentMethod(value, methodPath, obj, options);\n      }\n      if (value && typeof value === 'object') {\n        return createDeepProxy(value, methodPath, options);\n      }\n      return value;\n    }\n  });\n}\n\n/**\n * Instrument an OpenAI client with Sentry tracing\n * Can be used across Node.js, Cloudflare Workers, and Vercel Edge\n */\nfunction instrumentOpenAiClient(client, options) {\n  return createDeepProxy(client, '', options);\n}\nexport { instrumentOpenAiClient };","map":{"version":3,"names":["extractRequestAttributes","args","methodPath","attributes","GEN_AI_SYSTEM_ATTRIBUTE","GEN_AI_OPERATION_NAME_ATTRIBUTE","getOperationName","length","params","GEN_AI_REQUEST_MODEL_ATTRIBUTE","model","GEN_AI_REQUEST_TEMPERATURE_ATTRIBUTE","temperature","GEN_AI_REQUEST_TOP_P_ATTRIBUTE","top_p","GEN_AI_REQUEST_FREQUENCY_PENALTY_ATTRIBUTE","frequency_penalty","GEN_AI_REQUEST_PRESENCE_PENALTY_ATTRIBUTE","presence_penalty","setTokenUsageAttributes","span","promptTokens","completionTokens","totalTokens","undefined","setAttributes","OPENAI_USAGE_PROMPT_TOKENS_ATTRIBUTE","GEN_AI_USAGE_INPUT_TOKENS_ATTRIBUTE","OPENAI_USAGE_COMPLETION_TOKENS_ATTRIBUTE","GEN_AI_USAGE_OUTPUT_TOKENS_ATTRIBUTE","GEN_AI_USAGE_TOTAL_TOKENS_ATTRIBUTE","setCommonResponseAttributes","id","timestamp","OPENAI_RESPONSE_ID_ATTRIBUTE","GEN_AI_RESPONSE_ID_ATTRIBUTE","OPENAI_RESPONSE_MODEL_ATTRIBUTE","GEN_AI_RESPONSE_MODEL_ATTRIBUTE","OPENAI_RESPONSE_TIMESTAMP_ATTRIBUTE","Date","toISOString","addChatCompletionAttributes","response","created","usage","prompt_tokens","completion_tokens","total_tokens","Array","isArray","choices","finishReasons","map","choice","finish_reason","filter","reason","GEN_AI_RESPONSE_FINISH_REASONS_ATTRIBUTE","JSON","stringify","addResponsesApiAttributes","created_at","status","input_tokens","output_tokens","addResponseAttributes","result","recordOutputs","isChatCompletionResponse","responseTexts","message","content","GEN_AI_RESPONSE_TEXT_ATTRIBUTE","isResponsesApiResponse","output_text","addRequestAttributes","GEN_AI_REQUEST_MESSAGES_ATTRIBUTE","messages","input","getOptionsFromIntegration","scope","getCurrentScope","client","getClient","integration","getIntegrationByName","OPENAI_INTEGRATION_NAME","shouldRecordInputsAndOutputs","Boolean","getOptions","sendDefaultPii","recordInputs","options","instrumentMethod","originalMethod","context","instrumentedMethod","finalOptions","requestAttributes","operationName","startSpan","name","op","getSpanOperation","apply","error","captureException","createDeepProxy","target","currentPath","Proxy","get","obj","prop","value","buildMethodPath","String","shouldInstrument","instrumentOpenAiClient"],"sources":["/home/shawnstorie/sprkz-ng/sprkz-pdf-forms/node_modules/@sentry/core/src/utils/openai/index.ts"],"sourcesContent":["import { getCurrentScope } from '../../currentScopes';\nimport { captureException } from '../../exports';\nimport { startSpan } from '../../tracing/trace';\nimport type { Span, SpanAttributeValue } from '../../types-hoist/span';\nimport {\n  GEN_AI_OPERATION_NAME_ATTRIBUTE,\n  GEN_AI_REQUEST_FREQUENCY_PENALTY_ATTRIBUTE,\n  GEN_AI_REQUEST_MESSAGES_ATTRIBUTE,\n  GEN_AI_REQUEST_MODEL_ATTRIBUTE,\n  GEN_AI_REQUEST_PRESENCE_PENALTY_ATTRIBUTE,\n  GEN_AI_REQUEST_TEMPERATURE_ATTRIBUTE,\n  GEN_AI_REQUEST_TOP_P_ATTRIBUTE,\n  GEN_AI_RESPONSE_FINISH_REASONS_ATTRIBUTE,\n  GEN_AI_RESPONSE_ID_ATTRIBUTE,\n  GEN_AI_RESPONSE_MODEL_ATTRIBUTE,\n  GEN_AI_RESPONSE_TEXT_ATTRIBUTE,\n  GEN_AI_SYSTEM_ATTRIBUTE,\n  GEN_AI_USAGE_INPUT_TOKENS_ATTRIBUTE,\n  GEN_AI_USAGE_OUTPUT_TOKENS_ATTRIBUTE,\n  GEN_AI_USAGE_TOTAL_TOKENS_ATTRIBUTE,\n  OPENAI_RESPONSE_ID_ATTRIBUTE,\n  OPENAI_RESPONSE_MODEL_ATTRIBUTE,\n  OPENAI_RESPONSE_TIMESTAMP_ATTRIBUTE,\n  OPENAI_USAGE_COMPLETION_TOKENS_ATTRIBUTE,\n  OPENAI_USAGE_PROMPT_TOKENS_ATTRIBUTE,\n} from '../gen-ai-attributes';\nimport { OPENAI_INTEGRATION_NAME } from './constants';\nimport type {\n  InstrumentedMethod,\n  OpenAiChatCompletionObject,\n  OpenAiClient,\n  OpenAiIntegration,\n  OpenAiOptions,\n  OpenAiResponse,\n  OpenAIResponseObject,\n} from './types';\nimport {\n  buildMethodPath,\n  getOperationName,\n  getSpanOperation,\n  isChatCompletionResponse,\n  isResponsesApiResponse,\n  shouldInstrument,\n} from './utils';\n\n/**\n * Extract request attributes from method arguments\n */\nfunction extractRequestAttributes(args: unknown[], methodPath: string): Record<string, unknown> {\n  const attributes: Record<string, unknown> = {\n    [GEN_AI_SYSTEM_ATTRIBUTE]: 'openai',\n    [GEN_AI_OPERATION_NAME_ATTRIBUTE]: getOperationName(methodPath),\n  };\n\n  if (args.length > 0 && typeof args[0] === 'object' && args[0] !== null) {\n    const params = args[0] as Record<string, unknown>;\n\n    attributes[GEN_AI_REQUEST_MODEL_ATTRIBUTE] = params.model ?? 'unknown';\n    if ('temperature' in params) attributes[GEN_AI_REQUEST_TEMPERATURE_ATTRIBUTE] = params.temperature;\n    if ('top_p' in params) attributes[GEN_AI_REQUEST_TOP_P_ATTRIBUTE] = params.top_p;\n    if ('frequency_penalty' in params)\n      attributes[GEN_AI_REQUEST_FREQUENCY_PENALTY_ATTRIBUTE] = params.frequency_penalty;\n    if ('presence_penalty' in params) attributes[GEN_AI_REQUEST_PRESENCE_PENALTY_ATTRIBUTE] = params.presence_penalty;\n  } else {\n    attributes[GEN_AI_REQUEST_MODEL_ATTRIBUTE] = 'unknown';\n  }\n\n  return attributes;\n}\n\n/**\n * Helper function to set token usage attributes\n */\nfunction setTokenUsageAttributes(\n  span: Span,\n  promptTokens?: number,\n  completionTokens?: number,\n  totalTokens?: number,\n): void {\n  if (promptTokens !== undefined) {\n    span.setAttributes({\n      [OPENAI_USAGE_PROMPT_TOKENS_ATTRIBUTE]: promptTokens,\n      [GEN_AI_USAGE_INPUT_TOKENS_ATTRIBUTE]: promptTokens,\n    });\n  }\n  if (completionTokens !== undefined) {\n    span.setAttributes({\n      [OPENAI_USAGE_COMPLETION_TOKENS_ATTRIBUTE]: completionTokens,\n      [GEN_AI_USAGE_OUTPUT_TOKENS_ATTRIBUTE]: completionTokens,\n    });\n  }\n  if (totalTokens !== undefined) {\n    span.setAttributes({\n      [GEN_AI_USAGE_TOTAL_TOKENS_ATTRIBUTE]: totalTokens,\n    });\n  }\n}\n\n/**\n * Helper function to set common response attributes (ID, model, timestamp)\n */\nfunction setCommonResponseAttributes(span: Span, id?: string, model?: string, timestamp?: number): void {\n  if (id) {\n    span.setAttributes({\n      [OPENAI_RESPONSE_ID_ATTRIBUTE]: id,\n      [GEN_AI_RESPONSE_ID_ATTRIBUTE]: id,\n    });\n  }\n  if (model) {\n    span.setAttributes({\n      [OPENAI_RESPONSE_MODEL_ATTRIBUTE]: model,\n      [GEN_AI_RESPONSE_MODEL_ATTRIBUTE]: model,\n    });\n  }\n  if (timestamp) {\n    span.setAttributes({\n      [OPENAI_RESPONSE_TIMESTAMP_ATTRIBUTE]: new Date(timestamp * 1000).toISOString(),\n    });\n  }\n}\n\n/**\n * Add attributes for Chat Completion responses\n */\nfunction addChatCompletionAttributes(span: Span, response: OpenAiChatCompletionObject): void {\n  setCommonResponseAttributes(span, response.id, response.model, response.created);\n  if (response.usage) {\n    setTokenUsageAttributes(\n      span,\n      response.usage.prompt_tokens,\n      response.usage.completion_tokens,\n      response.usage.total_tokens,\n    );\n  }\n  if (Array.isArray(response.choices)) {\n    const finishReasons = response.choices\n      .map(choice => choice.finish_reason)\n      .filter((reason): reason is string => reason !== null);\n    if (finishReasons.length > 0) {\n      span.setAttributes({\n        [GEN_AI_RESPONSE_FINISH_REASONS_ATTRIBUTE]: JSON.stringify(finishReasons),\n      });\n    }\n  }\n}\n\n/**\n * Add attributes for Responses API responses\n */\nfunction addResponsesApiAttributes(span: Span, response: OpenAIResponseObject): void {\n  setCommonResponseAttributes(span, response.id, response.model, response.created_at);\n  if (response.status) {\n    span.setAttributes({\n      [GEN_AI_RESPONSE_FINISH_REASONS_ATTRIBUTE]: JSON.stringify([response.status]),\n    });\n  }\n  if (response.usage) {\n    setTokenUsageAttributes(\n      span,\n      response.usage.input_tokens,\n      response.usage.output_tokens,\n      response.usage.total_tokens,\n    );\n  }\n}\n\n/**\n * Add response attributes to spans\n * This currently supports both Chat Completion and Responses API responses\n */\nfunction addResponseAttributes(span: Span, result: unknown, recordOutputs?: boolean): void {\n  if (!result || typeof result !== 'object') return;\n\n  const response = result as OpenAiResponse;\n\n  if (isChatCompletionResponse(response)) {\n    addChatCompletionAttributes(span, response);\n    if (recordOutputs && response.choices?.length) {\n      const responseTexts = response.choices.map(choice => choice.message?.content || '');\n      span.setAttributes({ [GEN_AI_RESPONSE_TEXT_ATTRIBUTE]: JSON.stringify(responseTexts) });\n    }\n  } else if (isResponsesApiResponse(response)) {\n    addResponsesApiAttributes(span, response);\n    if (recordOutputs && response.output_text) {\n      span.setAttributes({ [GEN_AI_RESPONSE_TEXT_ATTRIBUTE]: response.output_text });\n    }\n  }\n}\n\n// Extract and record AI request inputs, if present. This is intentionally separate from response attributes.\nfunction addRequestAttributes(span: Span, params: Record<string, unknown>): void {\n  if ('messages' in params) {\n    span.setAttributes({ [GEN_AI_REQUEST_MESSAGES_ATTRIBUTE]: JSON.stringify(params.messages) });\n  }\n  if ('input' in params) {\n    span.setAttributes({ [GEN_AI_REQUEST_MESSAGES_ATTRIBUTE]: JSON.stringify(params.input) });\n  }\n}\n\nfunction getOptionsFromIntegration(): OpenAiOptions {\n  const scope = getCurrentScope();\n  const client = scope.getClient();\n  const integration = client?.getIntegrationByName(OPENAI_INTEGRATION_NAME) as OpenAiIntegration | undefined;\n  const shouldRecordInputsAndOutputs = integration ? Boolean(client?.getOptions().sendDefaultPii) : false;\n\n  return {\n    recordInputs: integration?.options?.recordInputs ?? shouldRecordInputsAndOutputs,\n    recordOutputs: integration?.options?.recordOutputs ?? shouldRecordInputsAndOutputs,\n  };\n}\n\n/**\n * Instrument a method with Sentry spans\n * Following Sentry AI Agents Manual Instrumentation conventions\n * @see https://docs.sentry.io/platforms/javascript/guides/node/tracing/instrumentation/ai-agents-module/#manual-instrumentation\n */\nfunction instrumentMethod<T extends unknown[], R>(\n  originalMethod: (...args: T) => Promise<R>,\n  methodPath: InstrumentedMethod,\n  context: unknown,\n  options?: OpenAiOptions,\n): (...args: T) => Promise<R> {\n  return async function instrumentedMethod(...args: T): Promise<R> {\n    const finalOptions = options || getOptionsFromIntegration();\n    const requestAttributes = extractRequestAttributes(args, methodPath);\n    const model = (requestAttributes[GEN_AI_REQUEST_MODEL_ATTRIBUTE] as string) || 'unknown';\n    const operationName = getOperationName(methodPath);\n\n    return startSpan(\n      {\n        name: `${operationName} ${model}`,\n        op: getSpanOperation(methodPath),\n        attributes: requestAttributes as Record<string, SpanAttributeValue>,\n      },\n      async (span: Span) => {\n        try {\n          if (finalOptions.recordInputs && args[0] && typeof args[0] === 'object') {\n            addRequestAttributes(span, args[0] as Record<string, unknown>);\n          }\n\n          const result = await originalMethod.apply(context, args);\n          // TODO: Add streaming support\n          addResponseAttributes(span, result, finalOptions.recordOutputs);\n          return result;\n        } catch (error) {\n          captureException(error);\n          throw error;\n        }\n      },\n    );\n  };\n}\n\n/**\n * Create a deep proxy for OpenAI client instrumentation\n */\nfunction createDeepProxy(target: object, currentPath = '', options?: OpenAiOptions): OpenAiClient {\n  return new Proxy(target, {\n    get(obj: object, prop: string): unknown {\n      const value = (obj as Record<string, unknown>)[prop];\n      const methodPath = buildMethodPath(currentPath, String(prop));\n\n      if (typeof value === 'function' && shouldInstrument(methodPath)) {\n        return instrumentMethod(value as (...args: unknown[]) => Promise<unknown>, methodPath, obj, options);\n      }\n\n      if (value && typeof value === 'object') {\n        return createDeepProxy(value as object, methodPath, options);\n      }\n\n      return value;\n    },\n  });\n}\n\n/**\n * Instrument an OpenAI client with Sentry tracing\n * Can be used across Node.js, Cloudflare Workers, and Vercel Edge\n */\nexport function instrumentOpenAiClient(client: OpenAiClient, options?: OpenAiOptions): OpenAiClient {\n  return createDeepProxy(client, '', options);\n}\n"],"mappings":";;;;;;;AA6CA;AACA;AACA;AACA,SAASA,wBAAwBA,CAACC,IAAI,EAAaC,UAAU,EAAmC;EAC9F,MAAMC,UAAU,GAA4B;IAC1C,CAACC,uBAAuB,GAAG,QAAQ;IACnC,CAACC,+BAA+B,GAAGC,gBAAgB,CAACJ,UAAU;EAClE,CAAG;EAED,IAAID,IAAI,CAACM,MAAA,GAAS,KAAK,OAAON,IAAI,CAAC,CAAC,MAAM,YAAYA,IAAI,CAAC,CAAC,MAAM,IAAI,EAAE;IACtE,MAAMO,MAAA,GAASP,IAAI,CAAC,CAAC;IAErBE,UAAU,CAACM,8BAA8B,IAAID,MAAM,CAACE,KAAA,IAAS,SAAS;IACtE,IAAI,iBAAiBF,MAAM,EAAEL,UAAU,CAACQ,oCAAoC,IAAIH,MAAM,CAACI,WAAW;IAClG,IAAI,WAAWJ,MAAM,EAAEL,UAAU,CAACU,8BAA8B,IAAIL,MAAM,CAACM,KAAK;IAChF,IAAI,uBAAuBN,MAAM,EAC/BL,UAAU,CAACY,0CAA0C,IAAIP,MAAM,CAACQ,iBAAiB;IACnF,IAAI,sBAAsBR,MAAM,EAAEL,UAAU,CAACc,yCAAyC,IAAIT,MAAM,CAACU,gBAAgB;EACrH,OAAS;IACLf,UAAU,CAACM,8BAA8B,IAAI,SAAS;EAC1D;EAEE,OAAON,UAAU;AACnB;;AAEA;AACA;AACA;AACA,SAASgB,uBAAuBA,CAC9BC,IAAI,EACJC,YAAY,EACZC,gBAAgB,EAChBC,WAAW,EACL;EACN,IAAIF,YAAA,KAAiBG,SAAS,EAAE;IAC9BJ,IAAI,CAACK,aAAa,CAAC;MACjB,CAACC,oCAAoC,GAAGL,YAAY;MACpD,CAACM,mCAAmC,GAAGN;IAC7C,CAAK,CAAC;EACN;EACE,IAAIC,gBAAA,KAAqBE,SAAS,EAAE;IAClCJ,IAAI,CAACK,aAAa,CAAC;MACjB,CAACG,wCAAwC,GAAGN,gBAAgB;MAC5D,CAACO,oCAAoC,GAAGP;IAC9C,CAAK,CAAC;EACN;EACE,IAAIC,WAAA,KAAgBC,SAAS,EAAE;IAC7BJ,IAAI,CAACK,aAAa,CAAC;MACjB,CAACK,mCAAmC,GAAGP;IAC7C,CAAK,CAAC;EACN;AACA;;AAEA;AACA;AACA;AACA,SAASQ,2BAA2BA,CAACX,IAAI,EAAQY,EAAE,EAAWtB,KAAK,EAAWuB,SAAS,EAAiB;EACtG,IAAID,EAAE,EAAE;IACNZ,IAAI,CAACK,aAAa,CAAC;MACjB,CAACS,4BAA4B,GAAGF,EAAE;MAClC,CAACG,4BAA4B,GAAGH;IACtC,CAAK,CAAC;EACN;EACE,IAAItB,KAAK,EAAE;IACTU,IAAI,CAACK,aAAa,CAAC;MACjB,CAACW,+BAA+B,GAAG1B,KAAK;MACxC,CAAC2B,+BAA+B,GAAG3B;IACzC,CAAK,CAAC;EACN;EACE,IAAIuB,SAAS,EAAE;IACbb,IAAI,CAACK,aAAa,CAAC;MACjB,CAACa,mCAAmC,GAAG,IAAIC,IAAI,CAACN,SAAA,GAAY,IAAI,CAAC,CAACO,WAAW;IACnF,CAAK,CAAC;EACN;AACA;;AAEA;AACA;AACA;AACA,SAASC,2BAA2BA,CAACrB,IAAI,EAAQsB,QAAQ,EAAoC;EAC3FX,2BAA2B,CAACX,IAAI,EAAEsB,QAAQ,CAACV,EAAE,EAAEU,QAAQ,CAAChC,KAAK,EAAEgC,QAAQ,CAACC,OAAO,CAAC;EAChF,IAAID,QAAQ,CAACE,KAAK,EAAE;IAClBzB,uBAAuB,CACrBC,IAAI,EACJsB,QAAQ,CAACE,KAAK,CAACC,aAAa,EAC5BH,QAAQ,CAACE,KAAK,CAACE,iBAAiB,EAChCJ,QAAQ,CAACE,KAAK,CAACG,YACrB,CAAK;EACL;EACE,IAAIC,KAAK,CAACC,OAAO,CAACP,QAAQ,CAACQ,OAAO,CAAC,EAAE;IACnC,MAAMC,aAAA,GAAgBT,QAAQ,CAACQ,OAAA,CAC5BE,GAAG,CAACC,MAAA,IAAUA,MAAM,CAACC,aAAa,EAClCC,MAAM,CAAEC,MAAM,IAAuBA,MAAA,KAAW,IAAI,CAAC;IACxD,IAAIL,aAAa,CAAC5C,MAAA,GAAS,CAAC,EAAE;MAC5Ba,IAAI,CAACK,aAAa,CAAC;QACjB,CAACgC,wCAAwC,GAAGC,IAAI,CAACC,SAAS,CAACR,aAAa;MAChF,CAAO,CAAC;IACR;EACA;AACA;;AAEA;AACA;AACA;AACA,SAASS,yBAAyBA,CAACxC,IAAI,EAAQsB,QAAQ,EAA8B;EACnFX,2BAA2B,CAACX,IAAI,EAAEsB,QAAQ,CAACV,EAAE,EAAEU,QAAQ,CAAChC,KAAK,EAAEgC,QAAQ,CAACmB,UAAU,CAAC;EACnF,IAAInB,QAAQ,CAACoB,MAAM,EAAE;IACnB1C,IAAI,CAACK,aAAa,CAAC;MACjB,CAACgC,wCAAwC,GAAGC,IAAI,CAACC,SAAS,CAAC,CAACjB,QAAQ,CAACoB,MAAM,CAAC;IAClF,CAAK,CAAC;EACN;EACE,IAAIpB,QAAQ,CAACE,KAAK,EAAE;IAClBzB,uBAAuB,CACrBC,IAAI,EACJsB,QAAQ,CAACE,KAAK,CAACmB,YAAY,EAC3BrB,QAAQ,CAACE,KAAK,CAACoB,aAAa,EAC5BtB,QAAQ,CAACE,KAAK,CAACG,YACrB,CAAK;EACL;AACA;;AAEA;AACA;AACA;AACA;AACA,SAASkB,qBAAqBA,CAAC7C,IAAI,EAAQ8C,MAAM,EAAWC,aAAa,EAAkB;EACzF,IAAI,CAACD,MAAA,IAAU,OAAOA,MAAA,KAAW,QAAQ,EAAE;EAE3C,MAAMxB,QAAA,GAAWwB,MAAA;EAEjB,IAAIE,wBAAwB,CAAC1B,QAAQ,CAAC,EAAE;IACtCD,2BAA2B,CAACrB,IAAI,EAAEsB,QAAQ,CAAC;IAC3C,IAAIyB,aAAA,IAAiBzB,QAAQ,CAACQ,OAAO,EAAE3C,MAAM,EAAE;MAC7C,MAAM8D,aAAA,GAAgB3B,QAAQ,CAACQ,OAAO,CAACE,GAAG,CAACC,MAAA,IAAUA,MAAM,CAACiB,OAAO,EAAEC,OAAA,IAAW,EAAE,CAAC;MACnFnD,IAAI,CAACK,aAAa,CAAC;QAAE,CAAC+C,8BAA8B,GAAGd,IAAI,CAACC,SAAS,CAACU,aAAa;MAAA,CAAG,CAAC;IAC7F;EACA,CAAE,MAAO,IAAII,sBAAsB,CAAC/B,QAAQ,CAAC,EAAE;IAC3CkB,yBAAyB,CAACxC,IAAI,EAAEsB,QAAQ,CAAC;IACzC,IAAIyB,aAAA,IAAiBzB,QAAQ,CAACgC,WAAW,EAAE;MACzCtD,IAAI,CAACK,aAAa,CAAC;QAAE,CAAC+C,8BAA8B,GAAG9B,QAAQ,CAACgC;MAAA,CAAa,CAAC;IACpF;EACA;AACA;;AAEA;AACA,SAASC,oBAAoBA,CAACvD,IAAI,EAAQZ,MAAM,EAAiC;EAC/E,IAAI,cAAcA,MAAM,EAAE;IACxBY,IAAI,CAACK,aAAa,CAAC;MAAE,CAACmD,iCAAiC,GAAGlB,IAAI,CAACC,SAAS,CAACnD,MAAM,CAACqE,QAAQ;IAAA,CAAG,CAAC;EAChG;EACE,IAAI,WAAWrE,MAAM,EAAE;IACrBY,IAAI,CAACK,aAAa,CAAC;MAAE,CAACmD,iCAAiC,GAAGlB,IAAI,CAACC,SAAS,CAACnD,MAAM,CAACsE,KAAK;IAAA,CAAG,CAAC;EAC7F;AACA;AAEA,SAASC,yBAAyBA,CAAA,EAAkB;EAClD,MAAMC,KAAA,GAAQC,eAAe,EAAE;EAC/B,MAAMC,MAAA,GAASF,KAAK,CAACG,SAAS,EAAE;EAChC,MAAMC,WAAA,GAAcF,MAAM,EAAEG,oBAAoB,CAACC,uBAAuB;EACxE,MAAMC,4BAAA,GAA+BH,WAAA,GAAcI,OAAO,CAACN,MAAM,EAAEO,UAAU,EAAE,CAACC,cAAc,IAAI,KAAK;EAEvG,OAAO;IACLC,YAAY,EAAEP,WAAW,EAAEQ,OAAO,EAAED,YAAA,IAAgBJ,4BAA4B;IAChFpB,aAAa,EAAEiB,WAAW,EAAEQ,OAAO,EAAEzB,aAAA,IAAiBoB;EAC1D,CAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA,SAASM,gBAAgBA,CACvBC,cAAc,EACd5F,UAAU,EACV6F,OAAO,EACPH,OAAO,EACqB;EAC5B,OAAO,eAAeI,kBAAkBA,CAAC,GAAG/F,IAAI,EAAiB;IAC/D,MAAMgG,YAAA,GAAeL,OAAA,IAAWb,yBAAyB,EAAE;IAC3D,MAAMmB,iBAAA,GAAoBlG,wBAAwB,CAACC,IAAI,EAAEC,UAAU,CAAC;IACpE,MAAMQ,KAAA,GAASwF,iBAAiB,CAACzF,8BAA8B,KAAgB,SAAS;IACxF,MAAM0F,aAAA,GAAgB7F,gBAAgB,CAACJ,UAAU,CAAC;IAElD,OAAOkG,SAAS,CACd;MACEC,IAAI,EAAE,GAACF,aAAA,IAAAzF,KAAA;MACA4F,EAAA,EAAAC,gBAAA,CAAArG,UAAA;MACAC,UAAA,EAAA+F;IACA,GACA,MAAA9E,IAAA;MACA;QACA,IAAA6E,YAAA,CAAAN,YAAA,IAAA1F,IAAA,cAAAA,IAAA;UACA0E,oBAAA,CAAAvD,IAAA,EAAAnB,IAAA;QACA;QAEA,MAAAiE,MAAA,SAAA4B,cAAA,CAAAU,KAAA,CAAAT,OAAA,EAAA9F,IAAA;QACA;QACAgE,qBAAA,CAAA7C,IAAA,EAAA8C,MAAA,EAAA+B,YAAA,CAAA9B,aAAA;QACA,OAAAD,MAAA;MACA,SAAAuC,KAAA;QACAC,gBAAA,CAAAD,KAAA;QACA,MAAAA,KAAA;MACA;IACA,CACA;EACA;AACA;;AAEA;AACA;AACA;AACA,SAAAE,gBAAAC,MAAA,EAAAC,WAAA,OAAAjB,OAAA;EACA,WAAAkB,KAAA,CAAAF,MAAA;IACAG,IAAAC,GAAA,EAAAC,IAAA;MACA,MAAAC,KAAA,GAAAF,GAAA,CAAAC,IAAA;MACA,MAAA/G,UAAA,GAAAiH,eAAA,CAAAN,WAAA,EAAAO,MAAA,CAAAH,IAAA;MAEA,WAAAC,KAAA,mBAAAG,gBAAA,CAAAnH,UAAA;QACA,OAAA2F,gBAAA,CAAAqB,KAAA,EAAAhH,UAAA,EAAA8G,GAAA,EAAApB,OAAA;MACA;MAEA,IAAAsB,KAAA,WAAAA,KAAA;QACA,OAAAP,eAAA,CAAAO,KAAA,EAAAhH,UAAA,EAAA0F,OAAA;MACA;MAEA,OAAAsB,KAAA;IACA;EACA;AACA;;AAEA;AACA;AACA;AACA;AACA,SAAAI,uBAAApC,MAAA,EAAAU,OAAA;EACA,OAAAe,eAAA,CAAAzB,MAAA,MAAAU,OAAA;AACA","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}